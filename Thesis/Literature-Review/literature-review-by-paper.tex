\newpage
\section{Literature Review - by Paper}
\label{sec_literature_review_by_paper}

\subsection{\textcite{LeeCarter1992}}The original paper of \textcite{LeeCarter1992}. 

\subsection{\textcite{HUNT_Villegas_2015}: Robustness and Convergence in the Lee-Carter Model with Cohort Effects}
Describes identifiability issues with cohort-extended Lee-Carter models. Connects this to the common two-step estimation procedure. Discusses lack of robustness in the full cohort-extended models in single-step estimation procedures (the closest procedure to our Bayesian model?). 

\textcite{Renshaw_Haberman_2006} have been under criticism; it converges slowly and is not robust to changes in the data. \textcite{Cairns_2009} suggests that this is due to an unresolved identifiability issue. \textcite{Renshaw_Haberman_2011} suggests that the issues observed by \textcite{Cairns_2009} originates from their fitting procedure. 

\textcite{HUNT_Villegas_2015}: Compares the two models, describes the identifiability mathematically, proposes a solution and quantifies the effect of the identifiability issues (?). 

\textcite{HUNT_Villegas_2015} states that the cohort-extended Lee-Carter model is 



\subsection{\textcite{BEUTNER_2017}}
Describes identifiability issues in cohort-extended Lee-Carter models, attempts to prove that there is identifiability under some assumptions for so-called plug-in models.
  
\subsection{\textcite{fung_peters_shevchenko_2017}}
\textbm{A unified approach to mortality modelling using state-space framework: characterisation, identification, estimation and forecasting}
Describes Bayesian state space Lee-Carter models. Does not consider cohort extensions thoroughly in this paper, but refers to \textcite{fung_peters_shevchenko_2019} that discusses this. Focus on implementing volality of the error term (heteroscedaticity). Some interesting discussion on previous Bayesian vs frequentist (usually two-step) procedures, and also discusses downsides of the MCMC approach for Bayesian inference. 

\subsection{\textcite{Currie_2016}} 
Uses the gnm (Generalized Non-Linear Model) library in $\texttt{R}$ to fit Lee-Carter and Renshaw-Haberman mortality models, when they are formulated as gnm´s (which seems to be quite close to our formulation). They assume Poisson distributed deaths, with a log link function for the force of mortality. They do not include an error term in the linear predictor. The implementation in gnm seems quite similar to the inlabru implementation, but not Bayesian (at least no priors are given). They report of convergence issues with the Renshaw-Haberman (cohort) model. In Section 8, they discuss the challenges of forecasting with cohort-based models; argues that one should not forecast age, period and cohort effects independently as they are not independent.

\subsection{\textcite{hunt_blake_2020}}
Paper containing proof that age-period-cohort models on the form
\begin{equation}
    \eta_{x,t} = \alpha_x + \sum_{i=1}^{N}\beta_x^{(i)}\kappa_t^{(i)} + \gamma_{t-x}
\end{equation}
does not have any identifiability issues that is not also present in the corresponding age-period model, as long as the $\beta_x^{(i)}$ is non-parametric. Also discusses independence of projected period and cohort effects?
  
\subsection{\textcite{Hunt_blake_2021}}
First impression: interesting discussion of uncertainty in cohort parameters. Discusses properties of cohort effects, for instance that $\mathbb{E}[\gamma_c]=0$ and that the cohort effects should be treated as independent of the period effects - in contrast to the discussion of \textcite{Currie_2016}. Raises an important key issue; the different cohort effects are estimated based on different amounts of data. Fewer observations of younger cohorts. Argues that estimates of cohort effects based on historical data should not be treated as known with some parameter uncertainty, but as an initial estimate of an ongoing process. They argue that the cohort effect should have the following properties:
\begin{itemize}
    \item The cohort effects should embody genuine lifelong mortality effects, and should not be a misclassification of age- or period effects. \textcite{Hunt_blake_2021} have solved this through a two-step procedure where age and period effects are fitted first, we should not have to worry about it since we use an identifiable non-parametric model. 
    \item Cohort parameters should lack trends, such that $\mathbb{E}[\gamma_{t-x}] = 0$. \textcite{Hunt_blake_2021} ensure this by choosing identifiability constraints that eliminate polynomial trends of first and second order. Again, I don´t think we have to worry about this. Although, this desired property does support the choice of a drift-less random walk to model the cohort effect. 
    \item The cohort effects should be stationary; the variability from the expected zero mean should not change with time (birth year). This property seems to simply be inspired by the argument that there is no apparent reason for the cohort effect to be non-stationary.
    \item The projected cohort effects should be independent of the projected period effects. This is discussed more thoroughly in \textcite{hunt_blake_2020}, and is in opposition (I think) to what is argued by \textcite{Currie_2016}. 
    \item The cohort projection should take "unusual" cohorts into account, for instance those with birth year during the war. Unusual mortality rates for these cohorts seems to be an effect of poor quality of data rather than of actual cohort effects. I do not think this will be very relevant for our data. 
\end{itemize}
They do point one flaw of the single-step fit-and-project procedure, which is that it might be less suitable if we want to use the fitted model for different data sets where other time series models might be more appropriate? (I don´t really see this point, it is in footnote of page S240. How would we use the model from one data set to fit values for another data set? Isn´t this model quite data-specific?) 
\subsubsection{Data Generating Process for Cohorts}
\textit{This is a bit too technical - we don´t do this, so it should only be mentioned briefly, if mentioned at all}
To incorporate uncertainty about recent cohorts, \textcite{Hunt_blake_2021} specifies the underlying "data generating process" of the cohort mortality. They introduce the following quantities:
\begin{itemize}
    \item 
\end{itemize}

\subsection{\textcite{Wong_Forster_2018}}:
Discusses Bayesian inference with the Poisson Lee-Carter model, where an error term for overdispersion is added. Discusses the added ability to correctly estimate uncertainty in the estimation when this extra term is included. Uses MCMC for model fitting, goes through this procedure thoroughly. Possible to use some of this procedure in our research? Does not include cohort effects, but discusses their presence in some of their results, and refers to future work on this topic. 

\subsection{\textcite{LiKogure2021}: Bayesian Mixture Modelling for Mortality Projection}
Contains some arguments on why a Bayesian approach is desirable. Not published in a very respected journal, so perhaps don´t cite it too much.  

\subsection{\textcite{Renshaw_Haberman_2011}: A Comparative Study of Parametric Mortality Projection Models}
A well-written paper, discussing different mortality models. Considers the Lee-Carter model as a Parametric model, which I am a little confused about. But does not consider the models in a Bayesian setting, and does not discuss identifiability beyond applying constraints on the effects. Considers a log-odds link function, and considers the cohort-Lee-Carter structure with an age-modulated cohort effect.
\newline
Actually, they consider four versions of what you would consider the Lee-Carter model (note, with a different link-function than yourself).
\newline
Instead of applying the model to the force of mortality, or cases of deaths $Y_{x,t}$ directly, \textcite{Renshaw_Haberman_2011} defines the model in relation to the probability of death $q_{x,t}$. They define the model on the log-odds of the probability of death:
\begin{equation*}
    \log\big(\frac{q_{x,t}}{1 - q_{x,t}}\big) = \eta_{x,t}.
\end{equation*}
They consider a range of precictor structures, and among these are four structures which can be considered as versions of the Lee-Carter model, with or without a cohort extension:
\begin{equation*}
    \begin{aligned}
    LC:\quad  \eta_{x,t} &= \alpha_x + \beta_x\kappa_t\\ 
    H_1:\quad  \eta_{x,t} &= \alpha_x + \beta_x\kappa_t + \iota_{t - x}\\
    M:\quad  \eta_{x,t} &= \lapha_x + \beta_x\kappa_t + \beta_x^{(0)}\iota_{t-x}\\
    LC2:\quad \eta_{x,t} &= \alpha_x + \beta_x^{(1)}\kappa_t^{(1)} + \beta_x^{(2)}\kappa_t^{(2)}
    \end{aligned}
\end{equation*}
They consider these in relation to the basic age-period-effect model:
\begin{equation*}
    H_0:\quad \eta_{x,t} = \alpha_x + \kappa_t + \iota_{t-x}.
\end{equation*}
There are some interesting things to note about this. \textcolor{myDarkGreen}{I am not quite sure if the LC2 model is meant to capture some cohort effects. } \textcite{Renshaw_Haberman_2011} conclude that the LC and the LC2 model give similar predictions for the probability of mortality. Secondly, because of the relationship
\begin{equation*}
    \text{cohort = period - age},
\end{equation*}
they apply a two-stage fitting strategy. \textcolor{myDarkGreen}{Sånn jeg tolker dette: two-stage fitting procedure er nødvendig PÅ GRUNN AV identifiability mellom age, period og cohort. Dette er interessant. }

Does not consider ages below 20, arguing that they are considering the model in an actuarial setting. Refers to \textcite{LeeCarter1992} and Renshaw and Haberman(2003a,b, 2006).. Give some interesting results: 
\begin{itemize}
    \item Their Lee-Carter cohort and theie Lee-Carter model produce the same predictions as the Lee-Carter cohort model.. (Note that this containts an age-modulating effect on the cohort effect). Note also that this does not at all seem to be the case for your data... So you can talk about differences in disease data and actuarial data?
    \item 
    
\end{itemize}
\textcolor{myDarkGreen}{MERK: Noe du lurer veldig på. Renshaw og Haberman refererer til disse som parametriske; spesifikt referer de til prediktorer på formen f.eks. $\eta_{x,t} = \alpha_x + \beta_x\kappa_t$} som parametriske. Hva innebærer dette? Er parametrisk i samme betydning som Hunt og Blake refererer til det i tilfellet fet $\beta_x$ må være non-parametric for at du skal ha identifiability?

\section{TODO: Cairns et al, 2008x3, 2009}
Renshaw and Haberman refererer mye til Cairns, de har modellene der $\beta_x = (x - \bar{x})$ osv. Ligner ikke så mye på det vi skal ha, men sikkert greit å nevne... 